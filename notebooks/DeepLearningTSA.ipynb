{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the feature generated in Feature engineering\n",
    "- notebooks/FeatureEngineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('../data/cleaned/train.csv', header=0, index_col=0)\n",
    "dataset = dataset.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Open', 'Promo', 'StateHoliday',\n",
       "       'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance',\n",
       "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
       "       'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'WeekOfYear',\n",
       "       'Year', 'Month', 'is_month_end', 'is_month_start', 'is_quarter_end',\n",
       "       'is_quarter_start', 'is_year_end', 'is_year_start',\n",
       "       'DistanceToNextHoliday', 'DistanceFromPrevHoliday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove columns that are not being predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in range(dataset.shape[1])]\n",
    "columns.remove(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gnerete Labled data for supervised learning using Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var4(t-1)  var1(t)   var2(t)   var3(t)   var4(t)  var5(t)  var6(t)  \\\n",
      "1   0.126664      0.0  0.500000  0.998937  0.120815      1.0      1.0   \n",
      "2   0.120815      0.0  0.333333  0.997875  0.115087      1.0      1.0   \n",
      "3   0.115087      0.0  0.166667  0.996812  0.120599      1.0      1.0   \n",
      "4   0.120599      0.0  0.000000  0.995749  0.146856      1.0      1.0   \n",
      "5   0.146856      0.0  1.000000  0.994686  0.000000      0.0      0.0   \n",
      "\n",
      "   var7(t)  var8(t)   var9(t)  ...  var19(t)  var20(t)  var21(t)  var22(t)  \\\n",
      "1      0.0      1.0  0.666667  ...       1.0  0.545455       0.0       0.0   \n",
      "2      0.0      1.0  0.666667  ...       1.0  0.545455       0.0       0.0   \n",
      "3      0.0      1.0  0.666667  ...       1.0  0.545455       0.0       0.0   \n",
      "4      0.0      1.0  0.666667  ...       1.0  0.545455       0.0       0.0   \n",
      "5      0.0      0.0  0.666667  ...       1.0  0.545455       0.0       0.0   \n",
      "\n",
      "   var23(t)  var24(t)  var25(t)  var26(t)  var27(t)  var28(t)  \n",
      "1       0.0       0.0       0.0       0.0  0.619048  0.934343  \n",
      "2       0.0       0.0       0.0       0.0  0.628571  0.933333  \n",
      "3       0.0       0.0       0.0       0.0  0.638095  0.932323  \n",
      "4       0.0       0.0       0.0       0.0  0.647619  0.931313  \n",
      "5       0.0       0.0       0.0       0.0  0.657143  0.930303  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "(1016880, 1, 28) (1016880,) (328, 1, 28) (328,)\n"
     ]
    }
   ],
   "source": [
    "reframed.drop(\n",
    "    reframed.columns[columns], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = (2*365+365//2)*1115\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM Regression model to predict the next sale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                15800     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,851\n",
      "Trainable params: 15,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 16:14:20.771215: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-11 16:14:20.771691: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1016880 samples, validate on 328 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 16:14:20.989072: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-11 16:14:20.989092: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-09-11 16:14:20.997191: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-09-11 16:14:21.016327: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-11 16:14:21.022027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-11 16:14:21.065372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-11 16:14:21.153422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016880/1016880 - 118s - loss: 0.0272 - val_loss: 0.0155 - 118s/epoch - 116us/sample\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/envs/10A/lib/python3.10/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2022-09-11 16:16:18.779846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016880/1016880 - 120s - loss: 0.0180 - val_loss: 0.0134 - 120s/epoch - 118us/sample\n",
      "Epoch 3/5\n",
      "1016880/1016880 - 119s - loss: 0.0157 - val_loss: 0.0130 - 119s/epoch - 117us/sample\n",
      "Epoch 4/5\n",
      "1016880/1016880 - 119s - loss: 0.0147 - val_loss: 0.0126 - 119s/epoch - 117us/sample\n",
      "Epoch 5/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=5, batch_size=72,\n",
    "                    validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/user/TENAC/week-1-4/Week-3/pharmaceutical-sales-prediction/notebooks/DeepLearningTSA.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/user/TENAC/week-1-4/Week-3/pharmaceutical-sales-prediction/notebooks/DeepLearningTSA.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_X \u001b[39m=\u001b[39m test_X\u001b[39m.\u001b[39mreshape((test_X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m, test_X\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/user/TENAC/week-1-4/Week-3/pharmaceutical-sales-prediction/notebooks/DeepLearningTSA.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# invert scaling for forecast\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/user/TENAC/week-1-4/Week-3/pharmaceutical-sales-prediction/notebooks/DeepLearningTSA.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m inv_yhat \u001b[39m=\u001b[39m concatenate((yhat, test_X[:, \u001b[39m1\u001b[39;49m:]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/user/TENAC/week-1-4/Week-3/pharmaceutical-sales-prediction/notebooks/DeepLearningTSA.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m inv_yhat \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(inv_yhat)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/user/TENAC/week-1-4/Week-3/pharmaceutical-sales-prediction/notebooks/DeepLearningTSA.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inv_yhat \u001b[39m=\u001b[39m inv_yhat[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0],1, test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 7.218\n",
      "Test R2: 0.986\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "r2 = r2_score(inv_y, inv_yhat)\n",
    "print('Test R2: %.3f' % r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Serialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mod\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "filename = 'models/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "pickle.dump(model,open('models/model.pkl','wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2be9f4616ca1b5198a62cd2082c7feed2682666a7b8fb219311f5849134be0bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
